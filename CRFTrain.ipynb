{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e969108-d8e3-4989-b8c0-520c2a293937",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "import nltk\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea219ca-aa74-48db-bc2e-bc8625a01c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install sklearn-crfsuite; ls /opt/conda/lib/python3.9/site-packages/sklearn_crfsuite/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "414177ac-9ec8-46a3-b7d1-94d9b6fcbd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce7079fc-21d8-49f8-82de-22ad1fd750ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lab_names = pd.read_csv('/home/jovyan/work/NER-Test/data/labtest_dictionary_v01.csv')\n",
    "# lab_names = lab_names['test'].tolist()\n",
    "\n",
    "lab_names = pd.read_csv('/home/jovyan/work/NER-Test/data/labtest_dictionary_train_cleaned.csv')\n",
    "lab_names = lab_names['test name'].tolist()\n",
    "\n",
    "UNITS = pd.read_csv('/home/jovyan/work/NER-Test/data/labtest_units_v02.csv')\n",
    "UNITS = UNITS['units'].tolist()\n",
    "UNITS = [str(u).upper() for u in UNITS]\n",
    "UNITS = list(set(UNITS))\n",
    "\n",
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"POS\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "\n",
    "def word2features(sent, i):\n",
    "    word = str(sent[i][0])\n",
    "    postag = str(sent[i][1])\n",
    "\n",
    "    isTestName = True if len([token for w in lab_names for token in str(w).upper().split(' ') if token.find(word)>-1])>0 else False\n",
    "    isUnit = True if word.upper() in UNITS else False\n",
    "    isDecimal = True if re.findall(r'(\\.)', word) and word.isdigit() else False\n",
    "    isDigit = True if word.isdigit() else False\n",
    "    isRange = True if re.match(r'\\d*.?\\d+-\\d*.?\\d+', word) else False\n",
    "    #isRange = True if re.match(r'\\(\\d+-\\d+\\)', word) else False\n",
    "    \n",
    "    features = {\n",
    "        'word.isTestName()': word if isTestName else '',\n",
    "        'word.isUnit()': word if isUnit else '',\n",
    "        'word.isDecimal()': word if isDecimal else '',\n",
    "        'word.isDigit()': word if isDigit else '',\n",
    "        'word.isRange()': word if isRange else '',\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    try:\n",
    "        if i > 0:\n",
    "            word1 = sent[i - 1][0]\n",
    "            postag1 = sent[i - 1][1]\n",
    "\n",
    "            isTestName1 = True if len([token for w in lab_names for token in str(w).upper().split(' ') if token.find(word)>-1])>0 else False\n",
    "            isUnit1 = True if word.upper() in UNITS else False\n",
    "            isDecimal1 = True if re.findall(r'(\\.)', word1) and word1.isdigit() else False\n",
    "            isDigit1 = True if word1.isdigit() else False\n",
    "            isRange1 = True if re.match(r'\\d*.?\\d+-\\d*.?\\d+', word1) else False\n",
    "\n",
    "            features.update({\n",
    "                '-1word.isTestName()': word1 if isTestName1 else '',\n",
    "                '-1word.isUnit()': word1 if isUnit1 else '',\n",
    "                '-1word.isDecimal()': word1 if isDecimal1 else '',\n",
    "                '-1word.isDigit()': word1 if isDigit1 else '',\n",
    "                '-1word.isRange()': word1 if isRange1 else '',\n",
    "                '-1postag': postag1,\n",
    "                '-1postag[:2]': postag1[:2],\n",
    "            })\n",
    "        else:\n",
    "            #features['BOS'] = True\n",
    "            features.update({\n",
    "                'BOS': word\n",
    "            })\n",
    "\n",
    "        if i < len(sent) - 1:\n",
    "            word1 = sent[i + 1][0]\n",
    "            postag1 = sent[i + 1][1]\n",
    "\n",
    "\n",
    "            isTestName1 = True if len([token for w in lab_names for token in str(w).upper().split(' ') if token.find(word)>-1])>0 else False\n",
    "            isUnit1 = True if word.upper() in UNITS else False\n",
    "            isDecimal1 = True if re.findall(r'(\\.)', word1) and word1.isdigit() else False\n",
    "            isDigit1 = True if word1.isdigit() else False\n",
    "            isRange1 = True if re.match(r'\\d*.?\\d+-\\d*.?\\d+', word1) else False\n",
    "\n",
    "            features.update({\n",
    "                '+1word.isTestName()': word1 if isTestName1 else '',\n",
    "                '+1word.isUnit()': word1 if isUnit1 else '',\n",
    "                '+1word.isDecimal()': word1 if isDecimal1 else '',\n",
    "                '+1word.isDigit()': word1 if isDigit1 else '',\n",
    "                '+1word.isRange()': word1 if isRange1 else '',\n",
    "                '+1postag': postag1,\n",
    "                '+1postag[:2]': postag1[:2],\n",
    "            })\n",
    "        else:\n",
    "            #features['EOS'] = True        \n",
    "            features.update({\n",
    "                'EOS': word\n",
    "            })\n",
    "    except:\n",
    "        print(sent,word)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]\n",
    "\n",
    "\n",
    "def extract_labs(t):\n",
    "    if len(t)<1:\n",
    "        return ['','']\n",
    "\n",
    "    t = re.sub(r'\\\"','',str(t).strip())    \n",
    "    t = re.sub(r'[^A-Z0-9-]',' ',str(t).strip().upper())            \n",
    "    t = re.sub(r'([\\s]*)(-)([\\s]*)',r'\\1 \\3',str(t).strip().upper())\n",
    "\n",
    "    wordlist = nltk.pos_tag(nltk.word_tokenize(str(t)))\n",
    "    tagged_list = []\n",
    "    for atagged in wordlist:\n",
    "        tagged_list.append([0,atagged[0],atagged[1]])\n",
    "    tagged_df = pd.DataFrame(tagged_list)\n",
    "    if tagged_df.shape[0]==0:\n",
    "        return ['','']\n",
    "    tagged_df = tagged_df.rename(columns={0:'Sentence #',1:'Word',2:'POS'})\n",
    "    \n",
    "    #print(tagged_df.head())\n",
    "    func = lambda s: [(w, p) for w, p in zip(s[\"Word\"].values.tolist(), s[\"POS\"].values.tolist())]\n",
    "    grouped = tagged_df.groupby(\"Sentence #\").apply(func)\n",
    "    sentences = [s for s in grouped]\n",
    "    test_sents = sentences\n",
    "    \n",
    "    X_test = [sent2features(s) for s in test_sents]\n",
    "    y_pred = crf_model.predict(X_test)\n",
    "    prediction = []\n",
    "    for sent, label in zip(test_sents,y_pred):\n",
    "        asent = []\n",
    "        atruth = []\n",
    "        apred = []\n",
    "        for s, l in zip(sent, label):\n",
    "            asent.append(s[0])\n",
    "\n",
    "            if l == 'LAB':\n",
    "                apred.append(s[0])\n",
    "        prediction.append([' '.join(asent), ' '.join(apred)])\n",
    "    sent, lab = prediction[0]    \n",
    "    return [sent, lab]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a83ac759-1886-46e4-97cf-ad91ceee1bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tagged_set(df_sent):\n",
    "\n",
    "    df_sent = df_sent.fillna(value='')\n",
    "\n",
    "    filtered = []\n",
    "    for key, values in df_sent.iterrows():\n",
    "        arow = []\n",
    "        for v in values:\n",
    "            \n",
    "            v = re.sub(r'\\\"','',str(v).strip())            \n",
    "            v = re.sub(r'[^A-Z0-9-]',' ',str(v).strip().upper())            \n",
    "            v = re.sub(r'([\\s]*)(-)([\\s]*)',r'\\1 \\3',str(v).strip().upper())\n",
    "            arow.append(v)\n",
    "\n",
    "        tags = []\n",
    "        term = ' '.join(arow[:-1])\n",
    "        wordlist = nltk.pos_tag(nltk.word_tokenize(term))        \n",
    "            \n",
    "        for i in range(len(wordlist)):\n",
    "            aword, apos = wordlist[i]\n",
    "            atag = arow[-1] if arow[-1]!='' else 'O'\n",
    "\n",
    "            tags.append((aword, apos, atag))\n",
    "\n",
    "        filtered.append(pd.DataFrame(tags))\n",
    "\n",
    "    tagged_list = []\n",
    "    for key, values in enumerate(filtered):\n",
    "        for k,atagged in values.iterrows():\n",
    "            tagged_list.append([key, atagged[0], atagged[1], atagged[2]])\n",
    "    tagged_df = pd.DataFrame(tagged_list)\n",
    "    tagged_df = tagged_df.rename(columns={0: 'Sentence #', 1: 'Word', 2: 'POS', 3: 'Tag'})\n",
    "    tagged_df.shape\n",
    "    \n",
    "    return tagged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f59af8-b63f-4c69-a806-d16d3776c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/jovyan/work/NER-Test/data/train/train_test_samples_v04.csv')\n",
    "data = data.dropna()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca5ae2a-07c3-47f4-88ef-be54a1a845e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/train/train_round1.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcc1cb8-322b-461d-8828-27fff5b7d2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['CLASS']=='LAB'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127a501f-b4dc-4398-84db-3205913335f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = data[:40000].copy()\n",
    "train = train.dropna(subset=['lab_result_0'])\n",
    "\n",
    "train_tagged = make_tagged_set(train)\n",
    "train_tagged = train_tagged.fillna(method=\"ffill\")\n",
    "words = list(set(train_tagged[\"Word\"].values))\n",
    "n_words = len(words)\n",
    "tags = list(set(train_tagged[\"Tag\"].values))\n",
    "n_tags = len(tags)\n",
    "getter = SentenceGetter(train_tagged)\n",
    "train_sentences = getter.sentences\n",
    "\n",
    "train_sents = train_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7136fc5d-344c-4a89-a043-e0b349dfb9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data[40000:].copy()\n",
    "test = test.dropna(subset=['lab_result_0'])\n",
    "test_tagged = make_tagged_set(test)\n",
    "test_tagged = test_tagged.fillna(method=\"ffill\")\n",
    "words = list(set(test_tagged[\"Word\"].values))\n",
    "n_words = len(words)\n",
    "tags = list(set(test_tagged[\"Tag\"].values))\n",
    "n_tags = len(tags)\n",
    "getter = SentenceGetter(test_tagged)\n",
    "test_sentences = getter.sentences\n",
    "test_sents = test_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa44572b-4c10-4673-b2ae-edaa35bfdda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent2features(train_sents[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb7a52e-3e81-4fe2-8ab8-b2514ff7d357",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfab538-6d09-4d13-bc7c-2b0d15ce516a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "X_test = [sent2features(s) for s in test_sents]\n",
    "y_test = [sent2labels(s) for s in test_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8dabcd-1813-42ae-8fbf-e8e5b3397ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48df16fa-8217-4fb2-b4c1-3495eb5e2340",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "labels = tags # list(crf.classes_)\n",
    "\n",
    "# define fixed parameters and parameters to search\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs', \n",
    "    max_iterations=100, \n",
    "    all_possible_transitions=True\n",
    ")\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}\n",
    "\n",
    "# use the same metric for evaluation\n",
    "f1_scorer = make_scorer(metrics.flat_f1_score, \n",
    "                        average='weighted', labels=labels)\n",
    "\n",
    "# search\n",
    "rs = RandomizedSearchCV(crf, params_space, \n",
    "                        cv=3, \n",
    "                        verbose=1, \n",
    "                        n_jobs=-1, \n",
    "                        n_iter=100, \n",
    "                        scoring=f1_scorer)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9495c36a-03e9-486b-8caf-1385c4d136f9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8749761b-4426-48ab-a1ed-8d532e3ca02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crf_model_lab_v01 all features\n",
    "# crf_model_lab_v02 add isDigital\n",
    "# crf_model_lab_v03 update BOS and EOS\n",
    "# crf_model_lab_v04 9000 training samples -- big impact\n",
    "# crf_model_lab_v05 fixed case insensitive\n",
    "# crf_model_lab_v06 fixed term matching no BOS EOS\n",
    "# crf_model_lab_v07 with BOS EOS --big impact\n",
    "# crf_model_lab_v08 for numbers, use isDigital only -- no impact # best setting\n",
    "# crf_model_lab_v09 use BOS EOS,add range pattern -- big impact cv score:0.9528583445541344, F1 Score: 0.845,0.964\n",
    "# crf_model_lab_v10 use isDigital, isDecimal -- CV:0.9505771665104099, F1:0.841, 0.963 \n",
    "# crf_model_lab_v11 use train_all_samples.csv\n",
    "# crf_model_lab v12 use labtest_dictionary.csv and labtest_units.csv\n",
    "# crf_model_lab v13 use train_test_samples.csv\n",
    "# crf_model_lab v14 use train_test_samples_v03.csv\n",
    "# crf_model_lab v15 use train_test_samples_v04.csv\n",
    "# crf_model_lab v16 use train_test_samples_v04.csv with training dictionary\n",
    "# crf_model_lab v16 use train_test_samples_v04.csv with training dictionary, labtest_units_v02.csv\n",
    "# crf_model_lab_round1_v01.pkl use train_round1.csv\n",
    "pickle.dump(rs, open('/home/jovyan/work/NER-Test/models/crf_model_lab_round1_v01.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da54fd8-7bd6-455f-8d23-5c623e71c0db",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a18ad18-ec6c-4a45-877a-9091f4700bf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# crf = rs.best_estimator_\n",
    "print('best params:', rs.best_params_)\n",
    "print('best CV score:', rs.best_score_)\n",
    "print('model size: {:0.2f}M'.format(rs.best_estimator_.size_ / 1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73fa61f-9b7f-4044-b601-82c53879ccdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = rs.best_estimator_\n",
    "y_pred = crf.predict(X_test)\n",
    "sorted_labels = tags\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c32e65-9be4-49f8-8cfa-03d5b446c63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "crf = rs.best_estimator_\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common(20))\n",
    "\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common()[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014f97f7-92e7-4347-89f3-b98a826b6b28",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-8s %s\" % (weight, label, attr))\n",
    "crf = rs.best_estimator_\n",
    "print(\"Top positive:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common(50))\n",
    "\n",
    "print(\"\\nTop negative:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common()[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1ea630-c03c-44c0-9282-182e36c8f354",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import eli5\n",
    "crf = rs.best_estimator_\n",
    "eli5.show_weights(crf, top=(30,30))\n",
    "#eli5.show_weights(crf, top=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284d7c62-56a5-47ff-926a-aa6c94679b58",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487b06b5-e544-4283-baf8-8b0719899b57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c05aa761-9669-4a2c-9dea-e306a0dbf61f",
   "metadata": {},
   "source": [
    "# Simple Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb7f17da-0f83-469a-bcb7-5b8df6d1135f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PLATELETS 434', '']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf_model = pickle.load(open('/home/jovyan/work/NER-Test/models/crf_model_lab_v17.pkl','rb'))\n",
    "v = 'PLATELETS                             434         '\n",
    "extract_labs(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa966c8-ea27-4e7f-9b3f-31d947c95426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c82e7b9-5b92-4aed-8506-b7bd574d1832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bd8ab3f-12d6-4ed7-987b-a2aeef932d7d",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b40c0c12-29a1-4eec-b93d-83e61a163273",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52min 22s, sys: 5.78 s, total: 52min 28s\n",
      "Wall time: 52min 31s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lab_result_0</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>lab_result</th>\n",
       "      <th>LAB_TEXT</th>\n",
       "      <th>LAB_TEST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Patient</td>\n",
       "      <td></td>\n",
       "      <td>[PATIENT, ]</td>\n",
       "      <td>PATIENT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Name    KIENTZ, SHERIL (65yo, F) ID# 6081528 A...</td>\n",
       "      <td></td>\n",
       "      <td>[NAME KIENTZ SHERIL 65YO F ID 6081528 APPT DAT...</td>\n",
       "      <td>NAME KIENTZ SHERIL 65YO F ID 6081528 APPT DATE...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DOB    05/28/1957</td>\n",
       "      <td></td>\n",
       "      <td>[DOB 05 28 1957, ]</td>\n",
       "      <td>DOB 05 28 1957</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Service Dept.    Holton Family Medicine</td>\n",
       "      <td></td>\n",
       "      <td>[SERVICE DEPT HOLTON FAMILY MEDICINE, ]</td>\n",
       "      <td>SERVICE DEPT HOLTON FAMILY MEDICINE</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Provider    MALIA WARNER MD</td>\n",
       "      <td></td>\n",
       "      <td>[PROVIDER MALIA WARNER MD, ]</td>\n",
       "      <td>PROVIDER MALIA WARNER MD</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        lab_result_0 CLASS  \\\n",
       "0                                            Patient         \n",
       "1  Name    KIENTZ, SHERIL (65yo, F) ID# 6081528 A...         \n",
       "2                                  DOB    05/28/1957         \n",
       "3            Service Dept.    Holton Family Medicine         \n",
       "4                        Provider    MALIA WARNER MD         \n",
       "\n",
       "                                          lab_result  \\\n",
       "0                                        [PATIENT, ]   \n",
       "1  [NAME KIENTZ SHERIL 65YO F ID 6081528 APPT DAT...   \n",
       "2                                 [DOB 05 28 1957, ]   \n",
       "3            [SERVICE DEPT HOLTON FAMILY MEDICINE, ]   \n",
       "4                       [PROVIDER MALIA WARNER MD, ]   \n",
       "\n",
       "                                            LAB_TEXT LAB_TEST  \n",
       "0                                            PATIENT           \n",
       "1  NAME KIENTZ SHERIL 65YO F ID 6081528 APPT DATE...           \n",
       "2                                     DOB 05 28 1957           \n",
       "3                SERVICE DEPT HOLTON FAMILY MEDICINE           \n",
       "4                           PROVIDER MALIA WARNER MD           "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "crf_model = pickle.load(open('/home/jovyan/work/NER-Test/models/crf_model_lab_v17.pkl','rb'))\n",
    "data = pd.read_csv('data/train/train_round2.csv')\n",
    "X_test = data.copy()\n",
    "X_test = X_test.fillna(value='')\n",
    "X_test['lab_result'] = X_test['lab_result_0'].apply(extract_labs)\n",
    "X_test['LAB_TEXT'] = X_test['lab_result'].apply(lambda s:s[0])\n",
    "X_test['LAB_TEST'] = X_test['lab_result'].apply(lambda s:s[1])\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7f6d3a7-6a8a-4ade-a8b0-ab9d461b75a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv('/home/jovyan/work/NER-Test/data/test/test-round2_v01.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3701a424-75a5-4681-9ce7-c6b7f2f3a9de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((38426, 6), (2841, 6))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_test.fillna(value='')\n",
    "\n",
    "X_test['check'] = X_test.apply(lambda s: True if s[1]=='LAB' and s[4]=='' else False, axis=1)\n",
    "X_test.shape, X_test[X_test['check']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e008a846-d6c3-413f-b03a-5388e1e04d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save misclassified\n",
    "X_test[X_test['check']].drop_duplicates(subset=['lab_result_0']).to_csv('/home/jovyan/work/NER-Test/data/test/test-round2-false_v01.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04a9c30f-372b-4103-8743-b0746d1f8448",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv('/home/jovyan/work/NER-Test/data/test/test-round2_v01.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af274406-f94b-42a2-a8e2-78b2b60709be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_verify = X_test.copy()\n",
    "df_verify['check'] = df_verify['lab_result_0'].apply(lambda s: True if str(s).upper().find('CHLORIDE')>-1 else False)\n",
    "df_verify[df_verify['check']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331c5bb6-e22f-4d24-a10b-5e472bf1777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_verify[df_verify['check']].to_csv('data/verify-CHLORIDE.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee3d18e-0253-47f5-aac8-6f7afac5c640",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "percent",
    "format_version": "1.3",
    "jupytext_version": "1.11.4"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
