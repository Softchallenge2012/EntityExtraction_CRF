{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e969108-d8e3-4989-b8c0-520c2a293937",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "import nltk\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea219ca-aa74-48db-bc2e-bc8625a01c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414177ac-9ec8-46a3-b7d1-94d9b6fcbd1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7079fc-21d8-49f8-82de-22ad1fd750ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lab_names = pd.read_csv('/home/jovyan/work/NER-Test/data/labtest_dictionary_v01.csv')\n",
    "# lab_names = lab_names['test'].tolist()\n",
    "\n",
    "lab_names = pd.read_csv('/home/jovyan/work/NER-Test/data/labtest_dictionary_train_cleaned_v04.csv')\n",
    "lab_names = lab_names['test name'].tolist()\n",
    "\n",
    "VALUES = pd.read_csv('/home/jovyan/work/NER-Test/data/labtest_additional_values.csv')\n",
    "VALUES = VALUES['values'].tolist()\n",
    "VALUES = [str(v).upper for v in VALUES]\n",
    "\n",
    "UNITS = pd.read_csv('/home/jovyan/work/NER-Test/data/labtest_units_v02.csv')\n",
    "UNITS = UNITS['units'].tolist()\n",
    "UNITS = [str(u).upper() for u in UNITS]\n",
    "UNITS = list(set(UNITS))\n",
    "\n",
    "ABNORMAL = pd.read_csv('/home/jovyan/work/NER-Test/data/labtest_abnormal.csv')\n",
    "ABNORMAL = ABNORMAL['abnormal flag'].tolist()\n",
    "ABNORMAL = [str(v).upper() for v in ABNORMAL]\n",
    "\n",
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"POS\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "\n",
    "def word2features(sent, i):\n",
    "    word = str(sent[i][0])\n",
    "    postag = str(sent[i][1])\n",
    "    \n",
    "    # values\n",
    "    # units\n",
    "    # references\n",
    "    # abnormal flags\n",
    "    # datetime\n",
    "    \n",
    "    isTestName = True if len([token for w in lab_names for token in str(w).upper().split(' ') if token.find(word)>-1])>0 else False\n",
    "    isValue = True if re.match(r'\\d*.?\\d+|[0-9\\.\\-\\s\\>\\<\\=]+', word) or word in VALUES else False    \n",
    "    isUnit = True if word.upper() in UNITS else False\n",
    "    isDecimal = True if re.findall(r'(\\.)', word) and word.isdigit() else False\n",
    "    isDigit = True if word.isdigit() else False\n",
    "    isRange = True if re.match(r'\\([0-9\\.\\-\\s\\>\\<\\=]+\\)', word) else False # match parenthesis+digits\n",
    "    isAbnormal = True if word.upper() in ABNORMAL else False\n",
    "    isDatetime = True if re.match(r'\\d{1,2}\\/\\d{1,2}\\/\\d{2,4}[\\s]+\\d{1,2}:\\d{1,2}[:\\d+]*|\\d{1,2}\\/\\d{1,2}\\/\\d{2,4}|\\d{1,2}:\\d{1,2}[:\\d+]*', str(word)) else False\n",
    "    #isRange = True if re.match(r'\\(\\d+-\\d+\\)', word) else False\n",
    "    \n",
    "    features = {\n",
    "        'word.isTestName()': word if isTestName else '',\n",
    "        'word.isValue()': word if isValue else '',\n",
    "        'word.isUnit()': word if isUnit else '',\n",
    "        'word.isDecimal()': word if isDecimal else '',\n",
    "        'word.isDigit()': word if isDigit else '',\n",
    "        'word.isRange()': word if isRange else '',\n",
    "        'word.isAbnormal()': word if isAbnormal else '',\n",
    "        'word.isDatetime()': word if isDatetime else '',\n",
    "        #'postag': postag,\n",
    "        #'postag[:2]': postag[:2],\n",
    "    }\n",
    "    try:\n",
    "        if i > 0:\n",
    "            word1 = sent[i - 1][0]\n",
    "            postag1 = sent[i - 1][1]\n",
    "\n",
    "            isTestName1 = True if len([token for w in lab_names for token in str(w).upper().split(' ') if token.find(word1)>-1])>0 else False\n",
    "            isValue1 = True if re.match(r'\\d*.?\\d+|[0-9\\.\\-\\s\\>\\<\\=]+', word1)  or word in VALUES else False    \n",
    "            isUnit1 = True if word1.upper() in UNITS else False\n",
    "            isDecimal1 = True if re.findall(r'(\\.)', word1) and word.isdigit() else False\n",
    "            isDigit1 = True if word1.isdigit() else False\n",
    "            isRange1 = True if re.match(r'\\([0-9\\.\\-\\s\\>\\<\\=]+\\)', word1) else False # match parenthesis+digits\n",
    "            isAbnormal1 = True if word1.upper() in ABNORMAL else False\n",
    "            isDatetime1 = True if re.match(r'\\d{1,2}\\/\\d{1,2}\\/\\d{2,4}[\\s]+\\d{1,2}:\\d{1,2}[:\\d+]*|\\d{1,2}\\/\\d{1,2}\\/\\d{2,4}|\\d{1,2}:\\d{1,2}[:\\d+]*', str(word1)) else False\n",
    "\n",
    "\n",
    "            features.update({\n",
    "                '-1word.isTestName()': word1 if isTestName1 else '',\n",
    "                '-1word.isValue()': word1 if isValue1 else '',\n",
    "                '-1word.isUnit()': word1 if isUnit1 else '',\n",
    "                '-1word.isDecimal()': word1 if isDecimal1 else '',\n",
    "                '-1word.isDigit()': word1 if isDigit1 else '',\n",
    "                '-1word.isRange()': word1 if isRange1 else '',\n",
    "                '-1word.isAbnormal()': word1 if isAbnormal1 else '',\n",
    "                '-1word.isDatetime()': word1 if isDatetime1 else '',\n",
    "                #'-1postag': postag1,\n",
    "                #'-1postag[:2]': postag1[:2],\n",
    "            })\n",
    "        else:\n",
    "            #features['BOS'] = True\n",
    "            features.update({\n",
    "                'BOS': word\n",
    "            })\n",
    "\n",
    "        if i < len(sent) - 1:\n",
    "            word1 = sent[i + 1][0]\n",
    "            postag1 = sent[i + 1][1]\n",
    "\n",
    "\n",
    "            isTestName1 = True if len([token for w in lab_names for token in str(w).upper().split(' ') if token.find(word1)>-1])>0 else False\n",
    "            isValue1 = True if re.match(r'\\d*.?\\d+|[0-9\\.\\-\\s\\>\\<\\=]+', word1)  or word in VALUES else False    \n",
    "            isUnit1 = True if word1.upper() in UNITS else False\n",
    "            isDecimal1 = True if re.findall(r'(\\.)', word1) and word.isdigit() else False\n",
    "            isDigit1 = True if word1.isdigit() else False\n",
    "            isRange1 = True if re.match(r'\\([0-9\\.\\-\\s\\>\\<\\=]+\\)', word1) else False # match parenthesis+digits\n",
    "            isAbnormal1 = True if word1.upper() in ABNORMAL else False\n",
    "            isDatetime1 = True if re.match(r'\\d{1,2}\\/\\d{1,2}\\/\\d{2,4}[\\s]+\\d{1,2}:\\d{1,2}[:\\d+]*|\\d{1,2}\\/\\d{1,2}\\/\\d{2,4}|\\d{1,2}:\\d{1,2}[:\\d+]*', str(word1)) else False\n",
    "\n",
    "\n",
    "            features.update({\n",
    "                '+1word.isTestName()': word1 if isTestName1 else '',\n",
    "                '+1word.isValue()': word1 if isValue1 else '',\n",
    "                '+1word.isUnit()': word1 if isUnit1 else '',\n",
    "                '+1word.isDecimal()': word1 if isDecimal1 else '',\n",
    "                '+1word.isDigit()': word1 if isDigit1 else '',\n",
    "                '+1word.isRange()': word1 if isRange1 else '',\n",
    "                '+1word.isAbnormal()': word1 if isAbnormal1 else '',\n",
    "                '+1word.isDatetime()': word1 if isDatetime1 else '',\n",
    "                #'+1postag': postag1,\n",
    "                #'+1postag[:2]': postag1[:2],\n",
    "            })\n",
    "        else:\n",
    "            #features['EOS'] = True        \n",
    "            features.update({\n",
    "                'EOS': word\n",
    "            })\n",
    "    except:\n",
    "        print(sent,word)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864c1502-2e20-4c3c-9865-3dd3a64200d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labs(t):\n",
    "    if len(t)<1:\n",
    "        return ['','','','','','','',]\n",
    "    \n",
    "    \n",
    "    #values = [re.sub(r'[\\\"|\\'\\[\\]]','',str(w)) for w in values]\n",
    "    v = t\n",
    "    v = re.sub(r'\\\"','',str(v).strip())            \n",
    "    v = re.sub(r'[^A-Z0-9\\:\\/\\-\\.\\(\\)]',' ',str(v).strip().upper())\n",
    "    #v = re.sub(r'([^\\s]+)([\\s]*-[\\s]*)([^\\s]+)',r'\\1-\\2',str(v).strip().upper())\n",
    "    v = re.sub(r'([^\\s]+)([\\s]*-[\\s]*)([^\\s]+)',r'\\1-\\3',str(v).strip().upper())\n",
    "    v = re.sub(r'(\\([A-Z\\s]+\\))','',str(v).strip().upper())\n",
    "    v = ','.join(re.split(r'[\\s]+',str(v)))\n",
    "    v = re.sub(r'(\\d{1,2}\\/\\d{1,2}\\/\\d{2,4})(,)(\\d{1,2}:\\d{1,2}[:\\d+]*)',r'\\1 \\3',v)\n",
    "    #values[0] = v\n",
    "    #arow.append(v)\n",
    "    tags = []\n",
    "    #print(values)\n",
    "    values = re.split(r',',str(t))\n",
    "    for v in values:\n",
    "        if re.search(r'[\\-|\\/|\\:]',v):\n",
    "            tags.append([0,v, 'CD'])\n",
    "        else:\n",
    "            wordlist = nltk.pos_tag(nltk.word_tokenize(v)) \n",
    "            for i in range(len(wordlist)):\n",
    "                aword, apos = wordlist[i]\n",
    "                tags.append([0,aword, apos])\n",
    "            \n",
    "    \n",
    "    tagged_df = pd.DataFrame(tags)\n",
    "    if tagged_df.shape[0]==0:\n",
    "        return ['','','','','','','',]\n",
    "    tagged_df = tagged_df.rename(columns={0:'Sentence #',1:'Word',2:'POS'})\n",
    "    \n",
    "    #print(tagged_df.head())\n",
    "    func = lambda s: [(w, p) for w, p in zip(s[\"Word\"].values.tolist(), s[\"POS\"].values.tolist())]\n",
    "    grouped = tagged_df.groupby(\"Sentence #\").apply(func)\n",
    "    sentences = [s for s in grouped]\n",
    "    test_sents = sentences\n",
    "    \n",
    "    X_test = [sent2features(s) for s in test_sents]\n",
    "    y_pred = crf_model.predict(X_test)\n",
    "    prediction = []\n",
    "    for sent, label in zip(test_sents,y_pred):\n",
    "        asent = []\n",
    "        aContext = []\n",
    "        aValue = []\n",
    "        aUnit = []\n",
    "        aRef = []\n",
    "        aAbnorm = []\n",
    "        aDtime = []\n",
    "        for s, l in zip(sent, label):\n",
    "            asent.append(s[0])\n",
    "\n",
    "            if l == 'O':\n",
    "                aContext.append(s[0])                \n",
    "            if l == 'VALUE':\n",
    "                aValue.append(s[0])\n",
    "            elif l == 'UNIT':\n",
    "                aUnit.append(s[0])\n",
    "            elif l == 'REF':\n",
    "                aRef.append(s[0])\n",
    "            elif l == 'ABNORM':\n",
    "                aAbnorm.append(s[0])\n",
    "            elif l == 'DTIME':\n",
    "                aDtime.append(s[0])\n",
    "                \n",
    "        prediction.append([' '.join(asent), ' '.join(aContext), ' '.join(aValue), \\\n",
    "                           ' '.join(aUnit), ' '.join(aRef), ' '.join(aAbnorm), ' '.join(aDtime), ','.join(label)])\n",
    "    sent, context,value,unit,ref,abnorm,dtime, pred = prediction[0]    \n",
    "    return [sent, context,value,unit,ref,abnorm,dtime, pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83ac759-1886-46e4-97cf-ad91ceee1bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tagged_set(df_sent):\n",
    "    # raw, lab name, value, unit, reference, abnormal flag, datetime\n",
    "    df_sent = df_sent.fillna(value='')\n",
    "\n",
    "    filtered = []\n",
    "    for key, values in df_sent.iterrows():\n",
    "        arow = []\n",
    "        values = [re.sub(r'[\\\"|\\'\\[\\]]','',str(w)) for w in values]\n",
    "        v = values[0]\n",
    "        v = re.sub(r'\\\"','',str(v).strip())            \n",
    "        v = re.sub(r'[^A-Z0-9\\:\\/\\-\\.\\(\\)]',' ',str(v).strip().upper())\n",
    "        #v = re.sub(r'([^\\s]+)([\\s]*-[\\s]*)([^\\s]+)',r'\\1-\\2',str(v).strip().upper())\n",
    "        v = re.sub(r'([^\\s]+)([\\s]*-[\\s]*)([^\\s]+)',r'\\1-\\3',str(v).strip().upper())\n",
    "        v = re.sub(r'(\\([A-Z\\s]+\\))','',str(v).strip().upper())\n",
    "        v = ','.join(re.split(r'[\\s]+',str(v)))\n",
    "        #v = re.sub(r'(\\d{1,2}\\/\\d{1,2}\\/\\d{2,4})(,)(\\d{1,2}:\\d{1,2}[:\\d+]*)',r'\\1 \\3',v)\n",
    "        v = re.sub(r'(\\d{1,2}\\/\\d{1,2}\\/\\d{2,4})(,)(\\d{1,2}:\\d{1,2}[:\\d+]*)','',v)\n",
    "        values[0] = v\n",
    "        #arow.append(v)\n",
    "        tags = []\n",
    "        #print(values)\n",
    "        for aword in re.split(r',',str(values[0])):\n",
    "            atag = ''\n",
    "            apos = ''\n",
    "            if len(values[2])>0 and len([w for w in values[2].split(',') if str(aword).upper()==str(w).upper()]) >0:\n",
    "                atag = 'VALUE'\n",
    "                apos = 'CD'\n",
    "                tags.append((aword, apos, atag))\n",
    "            elif len(values[3])>0 and len([w for w in values[3].split(',') if str(aword).upper()==str(w).upper()]) >0:\n",
    "                atag = 'UNIT'\n",
    "                apos = 'CD'\n",
    "                tags.append((aword, apos, atag))\n",
    "            elif len(values[4])>0 and len([w for w in values[4].split(',') if str(aword).upper()==str(w).upper()]) >0:\n",
    "                atag = 'REF'\n",
    "                apos = 'CD'\n",
    "                tags.append((aword, apos, atag))\n",
    "            elif len(values[5])>0 and len([w for w in values[5].split(',') if str(aword).upper()==str(w).upper()]) >0:\n",
    "                atag = 'ABNORM'\n",
    "                apos = 'NN'\n",
    "                tags.append((aword, apos, atag))\n",
    "            elif len(values[6])>0 and len([w for w in values[6].split(',') if str(aword).upper()==str(w).upper()]) >0:\n",
    "                atag = 'DTIME'\n",
    "                apos = 'CD'\n",
    "                tags.append((aword, apos, atag))\n",
    "            else:\n",
    "                atag = 'O'                \n",
    "                wordlist = nltk.pos_tag(nltk.word_tokenize(aword)) \n",
    "                for i in range(len(wordlist)):\n",
    "                    aword, apos = wordlist[i]\n",
    "                    tags.append((aword, apos, atag))\n",
    "        filtered.append(pd.DataFrame(tags))\n",
    "\n",
    "    tagged_list = []\n",
    "    for key, values in enumerate(filtered):\n",
    "        for k,atagged in values.iterrows():\n",
    "            tagged_list.append([key, atagged[0], atagged[1], atagged[2]])\n",
    "    tagged_df = pd.DataFrame(tagged_list)\n",
    "    tagged_df = tagged_df.rename(columns={0: 'Sentence #', 1: 'Word', 2: 'POS', 3: 'Tag'})\n",
    "    tagged_df.shape\n",
    "    \n",
    "    return tagged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f59af8-b63f-4c69-a806-d16d3776c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/jovyan/work/NER-Test/data/train/train_round123_v31_structured_v01.csv') \n",
    "data = data.dropna()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca5ae2a-07c3-47f4-88ef-be54a1a845e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/train/train_round123_v31_structured_v01.csv')\n",
    "data = data.fillna(value='')\n",
    "data['value'] = data['value'].apply(lambda s: [w for w in re.sub(r'[\\[|\\]]','',str(s)).split(',')])\n",
    "data['unit'] = data['unit'].apply(lambda s: [w for w in re.sub(r'[\\[|\\]]','',str(s)).split(',')])\n",
    "data['reference_range'] = data['reference_range'].apply(lambda s: [w for w in re.sub(r'[\\[|\\]]','',str(s)).split(',')])\n",
    "data['abnormal_flag'] = data['abnormal_flag'].apply(lambda s: [w for w in re.sub(r'[\\[|\\]]','',str(s)).split(',')])\n",
    "data['date_time'] = data['date_time'].apply(lambda s: [w for w in re.sub(r'[\\[|\\]]','',str(s)).split(',')])\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcc1cb8-322b-461d-8828-27fff5b7d2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dba849-57c0-404f-a2f0-9122ab8b79aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data/train/train_round123_v31_structured_v02.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd351b8-385a-47fa-abb3-0d6cadd535e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_data = pd.read_csv('data/test/train_round123_v31_structured_v02.csv')\n",
    "df_train_data[df_train_data['check']==False].to_csv('data/test/train_round123_v31_structured_v02_label_false.csv',index=False)\n",
    "df_train_data[df_train_data['check']==True].to_csv('data/test/train_round123_v31_structured_v02_label_true.csv',index=False)\n",
    "\n",
    "df_train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190aa18f-4cc6-41d7-bd12-c3d7cedf954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('data/test/train_round123_v31_structured_v02_label.csv')\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a92a117-18c1-47fb-a797-bbaee6bfe7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee943e4-0543-4db1-b7db-4ffa0b822162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09d9ce7-09a9-4ce9-a3b7-9f83e8743f83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ca7c2d-80a8-4e0c-a036-baf308f46be0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e8b472-5ebb-4581-9cbb-0fa0adac241a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7080e0d5-0aba-4fac-8f20-86d0db3e0562",
   "metadata": {},
   "source": [
    "# Load Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a54477-f7f0-4e68-bdea-ecab5fda7b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_data = pd.read_csv('data/train/train_round123_v31_structured_v02_label_true.csv')\n",
    "df_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127a501f-b4dc-4398-84db-3205913335f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_train_data.copy()\n",
    "train = train.dropna(subset=['lab_result_0'])\n",
    "train_tagged = make_tagged_set(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc08992-cbf4-4bba-a613-a0244f7d2fae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faadc28-4c90-4781-9edc-6b5cef24b546",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tagged['check'] = train_tagged[['Word','POS']].apply(lambda s: True if (s[0].isdigit() and float(s[0])<0) or re.search(r'[^A-Z]+',s[1]) else False, axis=1)\n",
    "train_tagged = train_tagged[train_tagged['check']==False].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef42891-ca2b-4e38-8f65-e51631669bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tagged.to_csv('data/train/train_round123_v31_structured_v02_tagged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf8677c-1e51-4fbf-bdc7-8611413b66d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tagged = train_tagged.fillna(method=\"ffill\")\n",
    "words = list(set(train_tagged[\"Word\"].values))\n",
    "n_words = len(words)\n",
    "tags = list(set(train_tagged[\"Tag\"].values))\n",
    "n_tags = len(tags)\n",
    "getter = SentenceGetter(train_tagged)\n",
    "train_sentences = getter.sentences\n",
    "train_sents = train_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f62b73-f333-4d49-8cbe-658c8f6e97f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_data = pd.read_csv('data/train/train_round123_v31_structured_v02_label_true.csv')\n",
    "df_test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7136fc5d-344c-4a89-a043-e0b349dfb9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_test_data.copy()\n",
    "test = test.dropna(subset=['lab_result_0'])\n",
    "test_tagged = make_tagged_set(test)\n",
    "\n",
    "\n",
    "test_tagged = test_tagged.fillna(method=\"ffill\")\n",
    "words = list(set(test_tagged[\"Word\"].values))\n",
    "n_words = len(words)\n",
    "tags = list(set(test_tagged[\"Tag\"].values))\n",
    "n_tags = len(tags)\n",
    "getter = SentenceGetter(test_tagged)\n",
    "test_sentences = getter.sentences\n",
    "test_sents = test_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa44572b-4c10-4673-b2ae-edaa35bfdda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent2features(train_sents[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb7a52e-3e81-4fe2-8ab8-b2514ff7d357",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfab538-6d09-4d13-bc7c-2b0d15ce516a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "X_test = [sent2features(s) for s in test_sents]\n",
    "y_test = [sent2labels(s) for s in test_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8dabcd-1813-42ae-8fbf-e8e5b3397ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48df16fa-8217-4fb2-b4c1-3495eb5e2340",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "labels = tags # list(crf.classes_)\n",
    "\n",
    "# define fixed parameters and parameters to search\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs', \n",
    "    max_iterations=100, \n",
    "    all_possible_transitions=True\n",
    ")\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9495c36a-03e9-486b-8caf-1385c4d136f9",
   "metadata": {
    "lines_to_next_cell": 2,
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "lr_poly = Pipeline([('polynomial_trans', PolynomialFeatures(20)),\n",
    "                    ('standard_scaler', StandardScaler()),\n",
    "                    ('crf', crf)])\n",
    "\n",
    "parameters = {'crf__algorithm':('lbfgs'), 'crf__max_iterations':[20,50,100]}\n",
    "clf = GridSearchCV(lr_poly, parameters)\n",
    "clf.fit(X,y)\n",
    "\n",
    "y_pred = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8749761b-4426-48ab-a1ed-8d532e3ca02e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5da54fd8-7bd6-455f-8d23-5c623e71c0db",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a18ad18-ec6c-4a45-877a-9091f4700bf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"Mean absolute error:\", metrics.mean_absolute_error(y, y_pred))\n",
    "print(\"Mean squared error:\", metrics.mean_squared_error(y, y_pred))\n",
    "print(\"R^2:\", metrics.r2_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73fa61f-9b7f-4044-b601-82c53879ccdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "colors = ['#ba2121ff', '#42a5f5ff', '#efa016ff', '#000000ff', '#6c5353ff']\n",
    "\n",
    "def fit_SGD(X, y, random_state, eta0, max_iter):\n",
    "    # SGD will perform much better if we scale the data!\n",
    "    X_scaled = StandardScaler().fit_transform(X)\n",
    "    return SGDRegressor(random_state=random_state, eta0=eta0, max_iter=max_iter).fit(X_scaled, y)\n",
    "\n",
    "coefs = []\n",
    "iterations = range(1, 100, 2)\n",
    "for n_iter in iterations:\n",
    "    sgd_regressor = fit_SGD(X, y, random_state=42, eta0=0.001, max_iter=n_iter)\n",
    "    coefs.append(sgd_regressor.coef_)\n",
    "\n",
    "for idx, c in enumerate(np.array(coefs).T):\n",
    "    plt.plot(iterations, c, label=r'$\\beta_{}$'.format(idx+1),\n",
    "            color=colors[idx])\n",
    "\n",
    "# Obtain same coefficients with LinearRegression:\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "lr = LinearRegression().fit(X_scaled, y);\n",
    "for coeff in lr.coef_:\n",
    "    plt.axhline(y=coeff, color='k', linestyle='--', alpha=0.3)\n",
    "    \n",
    "plt.ylabel(r'Optimal $\\beta$')\n",
    "plt.xlabel('Number of iteration steps')\n",
    "plt.title('Obtained Model Parameters vs. Number of Iteration Steps Taken')\n",
    "plt.legend(bbox_to_anchor=(1, 1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c32e65-9be4-49f8-8cfa-03d5b446c63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = lr_year_built.predict(X)\n",
    "\n",
    "plt.plot(X, y, 'o', color = 'k', label='training data')\n",
    "plt.plot(X, y_pred, color='#42a5f5ff', label='linear model prediction')\n",
    "plt.xlabel('Year built')\n",
    "plt.ylabel('Home price ($)')\n",
    "plt.legend()\n",
    "\n",
    "print(\"Training R^2:\", metrics.r2_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014f97f7-92e7-4347-89f3-b98a826b6b28",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "print('Training R^2:', metrics.r2_score(y, y_pred))\n",
    "\n",
    "plt.plot(X['YearBuilt'], y, 'o', color='k', label='training data')\n",
    "plt.plot(X['YearBuilt'], y_pred, color='#42a5f5ff', label='quadratic model prediction')\n",
    "plt.xlabel('Year built')\n",
    "plt.ylabel('Home price ($)')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1ea630-c03c-44c0-9282-182e36c8f354",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284d7c62-56a5-47ff-926a-aa6c94679b58",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487b06b5-e544-4283-baf8-8b0719899b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "for sent, true, pred in zip(test['lab_result_0'].tolist(),y_test,y_pred):   #y_pred = crf.predict(X_test)        \n",
    "    flag = (true == pred)\n",
    "    prediction.append([sent, true, pred,flag])\n",
    "df_pred = pd.DataFrame(prediction)\n",
    "test['true_label'] = df_pred[1]\n",
    "test['pred_label'] = df_pred[2]\n",
    "test['check'] = df_pred[3]                             \n",
    "test.to_csv('data/test/train_round123_v31_structured_v02_label_filtered.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05aa761-9669-4a2c-9dea-e306a0dbf61f",
   "metadata": {},
   "source": [
    "# Simple Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7f17da-0f83-469a-bcb7-5b8df6d1135f",
   "metadata": {},
   "outputs": [],
   "source": [
    "crf_model = pickle.load(open('/home/jovyan/work/NER-Test/models/crf_model_lab_round123_v031.pkl','rb'))\n",
    "v = 'WBC                  5.83 (OCT 08) 7.07 (OCT 07) 7.17 (OCT 06) 6.99 (OCT 05)'\n",
    "v =  re.sub(r'\\d{1,2}\\/\\d{1,2}\\/\\d{2,4}[\\s]+\\d{1,2}[:\\d{1,2}]+|\\d{1,2}\\/\\d{1,2}\\/\\d{2,4}','',str(v))\n",
    "v\n",
    "extract_labs(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa966c8-ea27-4e7f-9b3f-31d947c95426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c82e7b9-5b92-4aed-8506-b7bd574d1832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd35f6b4-4a2a-42a8-aa8f-f86c1f0c7867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bd8ab3f-12d6-4ed7-987b-a2aeef932d7d",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe3b803-89e6-4840-9ec9-9f03867227cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/train/train_round123_v31_structured_v02.csv')\n",
    "#data_freq = pd.read_csv('data/train/train_round12_freq.csv')\n",
    "data = data.fillna(value='')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40c0c12-29a1-4eec-b93d-83e61a163273",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "crf_model = pickle.load(open('/home/jovyan/work/NER-Test/models/crf_model_lab_round123_v031_structured_v02.pkl','rb'))\n",
    "#data = pd.read_csv('data/train/train_round3.csv')\n",
    "X_test = data.copy()\n",
    "X_test = X_test.fillna(value='')\n",
    "#sent, context,value,unit,ref,abnorm,dtime\n",
    "X_test['lab_result'] = X_test['lab_result_0'].apply(extract_labs)\n",
    "X_test['LAB_TEXT'] = X_test['lab_result'].apply(lambda s:s[0])\n",
    "X_test['LAB_TEST'] = X_test['lab_result'].apply(lambda s:s[1])\n",
    "X_test['LAB_VALUE'] = X_test['lab_result'].apply(lambda s:s[2])\n",
    "X_test['LAB_UNIT'] = X_test['lab_result'].apply(lambda s:s[3])\n",
    "X_test['LAB_REF'] = X_test['lab_result'].apply(lambda s:s[4])\n",
    "X_test['LAB_ABNORM'] = X_test['lab_result'].apply(lambda s:s[5])\n",
    "X_test['LAB_DTIME'] = X_test['lab_result'].apply(lambda s:s[6])\n",
    "X_test['LAB_PRED'] = X_test['lab_result'].apply(lambda s:s[7])\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f6d3a7-6a8a-4ade-a8b0-ab9d461b75a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv('/home/jovyan/work/NER-Test/data/test/train_round123_v31_structured_v02_v02.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3701a424-75a5-4681-9ce7-c6b7f2f3a9de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a9c30f-372b-4103-8743-b0746d1f8448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0e1577a-8249-4376-b342-fa1e5969be18",
   "metadata": {},
   "source": [
    "# Performance of frequent tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331c5bb6-e22f-4d24-a10b-5e472bf1777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv('data/train/train_round123_validated_v31.csv')\n",
    "df_data_freq = pd.read_csv('data/train/train_round123_validated_freq_v31.csv')\n",
    "df_data = df_data.fillna(value='')\n",
    "df_data_freq = df_data_freq[df_data_freq['freq']>2][['lab_result_0','CLASS']].copy()\n",
    "df_data = pd.concat([df_data[df_data['CLASS']==''],df_data_freq])\n",
    "df_data['lab_result_0'] = df_data['lab_result_0'].apply(lambda s: re.sub(r'\\d{1,2}\\/\\d{1,2}\\/\\d{2,4}[\\s]+\\d{1,2}[:\\d{1,2}]+|\\d{1,2}\\/\\d{1,2}\\/\\d{2,4}|\\d{1,2}[:\\d{1,2}]+','',str(s)).strip())\n",
    "df_data = df_data.fillna(value='')\n",
    "df_data['select'] = df_data['lab_result_0'].apply(lambda s: False if len(str(s).strip())<1 else True)\n",
    "df_data = df_data[df_data['select']][['lab_result_0','CLASS']].copy()\n",
    "\n",
    "df_data = df_data.fillna(value='')\n",
    "df_data['lab_result'] = df_data['lab_result_0'].apply(extract_labs)\n",
    "df_data['LAB_TEXT'] = df_data['lab_result'].apply(lambda s:s[0])\n",
    "df_data['LAB_TEST'] = df_data['lab_result'].apply(lambda s:s[1])\n",
    "\n",
    "df_data['check'] = df_data.apply(lambda s: True if s[1]=='LAB' and s[4]=='' else False, axis=1)\n",
    "df_data.to_csv('/home/jovyan/work/NER-Test/data/test/train_round123_validated_v32_freq.csv',index=False)\n",
    "df_data.shape, df_data[df_data['check']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee3d18e-0253-47f5-aac8-6f7afac5c640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Lab samples \n",
    "df_train_data.shape, df_data_freq[df_data_freq['freq']>2].shape, data.shape, data[data['CLASS']=='LAB'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef82ccef-bd94-4466-ab2a-124b3ad973db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "percent",
    "format_version": "1.3",
    "jupytext_version": "1.11.4"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
